{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArslanNustian116/HLS4ML_Pycon2024/blob/main/ML_Workshop_Stuff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UzU-6vcYN6sY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUzrQzCEQ2dA"
      },
      "source": [
        "# Fetch Jet Tagging Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcAkAsADPJPz",
        "outputId": "2c670dce-d0af-4502-c908-e96384e4bf4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['zlogz', 'c1_b0_mmdt', 'c1_b1_mmdt', 'c1_b2_mmdt', 'c2_b1_mmdt', 'c2_b2_mmdt', 'd2_b1_mmdt', 'd2_b2_mmdt', 'd2_a1_b1_mmdt', 'd2_a1_b2_mmdt', 'm2_b1_mmdt', 'm2_b2_mmdt', 'n2_b1_mmdt', 'n2_b2_mmdt', 'mass_mmdt', 'multiplicity']\n",
            "(830000, 16) (830000,)\n",
            "      zlogz  c1_b0_mmdt  c1_b1_mmdt  c1_b2_mmdt  c2_b1_mmdt  c2_b2_mmdt  \\\n",
            "0 -2.935125    0.383155    0.005126    0.000084    0.009070    0.000179   \n",
            "1 -1.927335    0.270699    0.001585    0.000011    0.003232    0.000029   \n",
            "2 -3.112147    0.458171    0.097914    0.028588    0.124278    0.038487   \n",
            "3 -2.666515    0.437068    0.049122    0.007978    0.047477    0.004802   \n",
            "4 -2.484843    0.428981    0.041786    0.006110    0.023066    0.001123   \n",
            "\n",
            "   d2_b1_mmdt  d2_b2_mmdt  d2_a1_b1_mmdt  d2_a1_b2_mmdt  m2_b1_mmdt  \\\n",
            "0    1.769445    2.123898       1.769445       0.308185    0.135687   \n",
            "1    2.038834    2.563099       2.038834       0.211886    0.063729   \n",
            "2    1.269254    1.346238       1.269254       0.246488    0.115636   \n",
            "3    0.966505    0.601864       0.966505       0.160756    0.082196   \n",
            "4    0.552002    0.183821       0.552002       0.084338    0.048006   \n",
            "\n",
            "   m2_b2_mmdt  n2_b1_mmdt  n2_b2_mmdt   mass_mmdt  multiplicity  \n",
            "0    0.083278    0.412136    0.299058    8.926882          75.0  \n",
            "1    0.036310    0.310217    0.226661    3.886512          31.0  \n",
            "2    0.079094    0.357559    0.289220  162.144669          61.0  \n",
            "3    0.033311    0.238871    0.094516   91.258934          39.0  \n",
            "4    0.014450    0.141906    0.036665   79.725777          35.0  \n",
            "0    g\n",
            "1    w\n",
            "2    t\n",
            "3    z\n",
            "4    w\n",
            "Name: class, dtype: category\n",
            "Categories (5, object): ['g', 'q', 't', 'w', 'z']\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "data = fetch_openml('hls4ml_lhc_jets_hlf')\n",
        "X, y = data['data'], data['target']\n",
        "\n",
        "print(data['feature_names'])\n",
        "print(X.shape, y.shape)\n",
        "print(X[:5])\n",
        "print(y[:5])\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y = to_categorical(y, 5)\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(y[:5])\n",
        "scaler = StandardScaler()\n",
        "X_train_val = scaler.fit_transform(X_train_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "np.save('X_train_val.npy', X_train_val)\n",
        "np.save('X_test.npy', X_test)\n",
        "np.save('y_train_val.npy', y_train_val)\n",
        "np.save('y_test.npy', y_test)\n",
        "np.save('classes.npy', le.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c5fOcZmZOD1o"
      },
      "outputs": [],
      "source": [
        "import callbacks\n",
        "\n",
        "X_train_val = np.load('X_train_val.npy')\n",
        "X_test = np.load('X_test.npy')\n",
        "y_train_val = np.load('y_train_val.npy')\n",
        "y_test = np.load('y_test.npy')\n",
        "classes = np.load('classes.npy', allow_pickle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNS3TkDRRBHK"
      },
      "source": [
        "# Define a Base Line Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hMpS5EAHORzf",
        "outputId": "8a6a33ce-5efc-484a-f276-96df0118ce6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from callbacks import all_callbacks\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_shape=(16,), name='fc1', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "model.add(Activation(activation='relu', name='relu1'))\n",
        "model.add(Dense(32, name='fc2', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "model.add(Activation(activation='relu', name='relu2'))\n",
        "model.add(Dense(32, name='fc3', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "model.add(Activation(activation='relu', name='relu3'))\n",
        "model.add(Dense(5, name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "model.add(Activation(activation='softmax', name='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoyThhXqRWFI"
      },
      "source": [
        "# Train the Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Created on 7 Apr 2017\n",
        "\n",
        "@author: jkiesele\n",
        "'''\n",
        "\n",
        "import json\n",
        "\n",
        "# loss per epoch\n",
        "from time import time\n",
        "\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, History, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "\n",
        "\n",
        "class newline_callbacks_begin(Callback):\n",
        "    def __init__(self, outputDir):\n",
        "        self.outputDir = outputDir\n",
        "        self.loss = []\n",
        "        self.val_loss = []\n",
        "        self.full_logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, epoch_logs={}):  # noqa: B006\n",
        "        import os\n",
        "\n",
        "        lossfile = os.path.join(self.outputDir, 'losses.log')\n",
        "        print('\\n***callbacks***\\nsaving losses to ' + lossfile)\n",
        "        self.loss.append(epoch_logs.get('loss'))\n",
        "        self.val_loss.append(epoch_logs.get('val_loss'))\n",
        "        f = open(lossfile, 'w')\n",
        "        for i in range(len(self.loss)):\n",
        "            f.write(str(self.loss[i]))\n",
        "            f.write(\" \")\n",
        "            f.write(str(self.val_loss[i]))\n",
        "            f.write(\"\\n\")\n",
        "        f.close()\n",
        "        normed = {}\n",
        "        for vv in epoch_logs:\n",
        "            normed[vv] = float(epoch_logs[vv])\n",
        "        self.full_logs.append(normed)\n",
        "        lossfile = os.path.join(self.outputDir, 'full_info.log')\n",
        "        with open(lossfile, 'w') as out:\n",
        "            out.write(json.dumps(self.full_logs))\n",
        "\n",
        "\n",
        "class newline_callbacks_end(Callback):\n",
        "    def on_epoch_end(self, epoch, epoch_logs={}):  # noqa: B006\n",
        "        print('\\n***callbacks end***\\n')\n",
        "\n",
        "\n",
        "class Losstimer(Callback):\n",
        "    def __init__(self, every=5):\n",
        "        self.points = []\n",
        "        self.every = every\n",
        "\n",
        "    def on_train_begin(self, logs):\n",
        "        self.start = time()\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        if (batch % self.every) != 0:\n",
        "            return\n",
        "        elapsed = time() - self.start\n",
        "        cop = {}\n",
        "        for i, j in logs.items():\n",
        "            cop[i] = float(j)\n",
        "        cop['elapsed'] = elapsed\n",
        "        self.points.append(cop)\n",
        "\n",
        "\n",
        "class all_callbacks:\n",
        "    def __init__(\n",
        "        self, stop_patience=10, lr_factor=0.5, lr_patience=1, lr_epsilon=0.001, lr_cooldown=4, lr_minimum=1e-5, outputDir=''\n",
        "    ):\n",
        "        self.nl_begin = newline_callbacks_begin(outputDir)\n",
        "        self.nl_end = newline_callbacks_end()\n",
        "\n",
        "        self.stopping = EarlyStopping(monitor='val_loss', patience=stop_patience, verbose=1, mode='min')\n",
        "\n",
        "        self.reduce_lr = ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=lr_factor,\n",
        "            patience=lr_patience,\n",
        "            mode='min',\n",
        "            verbose=1,\n",
        "            epsilon=lr_epsilon,\n",
        "            cooldown=lr_cooldown,\n",
        "            min_lr=lr_minimum,\n",
        "        )\n",
        "\n",
        "        self.modelbestcheck = ModelCheckpoint(\n",
        "            outputDir + \"/KERAS_check_best_model.keras\", monitor='val_loss', verbose=1, save_best_only=True,save_format='h5'\n",
        "        )\n",
        "\n",
        "        self.modelbestcheckweights = ModelCheckpoint(\n",
        "            outputDir + \"/KERAS_check_best_model_weights.keras\",\n",
        "            monitor='val_loss',\n",
        "            verbose=1,\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True\n",
        "        )\n",
        "\n",
        "        self.modelcheckperiod = ModelCheckpoint(outputDir + \"/KERAS_check_model_epoch{epoch:02d}.keras\", verbose=1, period=10)\n",
        "\n",
        "        self.modelcheck = ModelCheckpoint(outputDir + \"/KERAS_check_model_last.keras\", verbose=1)\n",
        "\n",
        "        self.modelcheckweights = ModelCheckpoint(\n",
        "            outputDir + \"/KERAS_check_model_last_weights.keras\", verbose=1,save_weights_only=True\n",
        "        )\n",
        "\n",
        "        self.tb = TensorBoard(log_dir=outputDir + '/logs')\n",
        "\n",
        "        self.history = History()\n",
        "        self.timer = Losstimer()\n",
        "\n",
        "        self.callbacks = [\n",
        "            self.nl_begin,\n",
        "            self.modelbestcheck,\n",
        "            self.modelbestcheckweights,\n",
        "            self.modelcheck,\n",
        "            self.modelcheckweights,\n",
        "            self.modelcheckperiod,\n",
        "            self.reduce_lr,\n",
        "            self.stopping,\n",
        "            self.nl_end,\n",
        "            self.tb,\n",
        "            self.history,\n",
        "            self.timer,\n",
        "        ]\n"
      ],
      "metadata": {
        "id": "BBPSpYhtuLhI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3acRclO2RZdv",
        "outputId": "8557b236-55c1-4db3-f689-9f6e3df43860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'module' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-af6eaa395e3a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0madam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     callbacks = callbacks(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mstop_patience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlr_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ],
      "source": [
        "train = True\n",
        "if train:\n",
        "    adam = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
        "    callbacks = all_callbacks(\n",
        "        stop_patience=1000,\n",
        "        lr_factor=0.5,\n",
        "        lr_patience=10,\n",
        "        lr_epsilon=0.000001,\n",
        "        lr_cooldown=2,\n",
        "        lr_minimum=0.0000001,\n",
        "        outputDir='model_1',\n",
        "    )\n",
        "    model.fit(\n",
        "        X_train_val,\n",
        "        y_train_val,\n",
        "        batch_size=1024,\n",
        "        epochs=30,\n",
        "        validation_split=0.25,\n",
        "        shuffle=True,\n",
        "        callbacks=callbacks.callbacks,\n",
        "    )\n",
        "else:\n",
        "    from tensorflow.keras.models import load_model\n",
        "\n",
        "    model = load_model('model_1/KERAS_check_best_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaG1l2iKQy8W"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X819j75bRG5q"
      },
      "source": [
        "# Setting Pruning Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQNY0l10OS7a"
      },
      "outputs": [],
      "source": [
        "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
        "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
        "\n",
        "pruning_params = {\"pruning_schedule\": pruning_schedule.ConstantSparsity(0.75, begin_step=2000, frequency=100)}\n",
        "model = prune.prune_low_magnitude(model, **pruning_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPrrf2KgRc8H"
      },
      "source": [
        "# Train Pruned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ICX1429OXyC"
      },
      "outputs": [],
      "source": [
        "train = True\n",
        "if train:\n",
        "    adam = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
        "    callbacks = all_callbacks(\n",
        "        stop_patience=1000,\n",
        "        lr_factor=0.5,\n",
        "        lr_patience=10,\n",
        "        lr_epsilon=0.000001,\n",
        "        lr_cooldown=2,\n",
        "        lr_minimum=0.0000001,\n",
        "        outputDir='model_2',\n",
        "    )\n",
        "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
        "    model.fit(\n",
        "        X_train_val,\n",
        "        y_train_val,\n",
        "        batch_size=1024,\n",
        "        epochs=30,\n",
        "        validation_split=0.25,\n",
        "        shuffle=True,\n",
        "        callbacks=callbacks.callbacks,\n",
        "    )\n",
        "    # Save the model again but with the pruning 'stripped' to use the regular layer types\n",
        "    model = strip_pruning(model)\n",
        "    model.save('model_2/KERAS_check_best_model.h5')\n",
        "else:\n",
        "    from tensorflow.keras.models import load_model\n",
        "\n",
        "    model = load_model('model_2/KERAS_check_best_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01AI8aJYSGo_"
      },
      "source": [
        "# Observing the Weights after Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt9m32nPUszo"
      },
      "outputs": [],
      "source": [
        "w = model.layers[0].weights[0].numpy()\n",
        "h, b = np.histogram(w, bins=100)\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.bar(b[:-1], h, width=b[1] - b[0])\n",
        "plt.semilogy()\n",
        "print('% of zeros = {}'.format(np.sum(w == 0) / np.size(w)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxJzNxFkSSER"
      },
      "source": [
        "# Compare Accuracy of Baseline and Pruned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBRkM6XSWjpB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_ref = load_model('model_1/KERAS_check_best_model.h5')\n",
        "\n",
        "y_ref = model_ref.predict(X_test)\n",
        "y_prune = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy unpruned: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_ref, axis=1))))\n",
        "print(\"Accuracy pruned:   {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_prune, axis=1))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP7RXnhoSbV2"
      },
      "source": [
        "# Create HLS Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98yQsKZtZtYA"
      },
      "outputs": [],
      "source": [
        "!pip install hls4ml\n",
        "\n",
        "import hls4ml\n",
        "\n",
        "config = hls4ml.utils.config_from_keras_model(model, granularity='model')\n",
        "print(config)\n",
        "hls_model = hls4ml.converters.convert_from_keras_model(\n",
        "    model, hls_config=config, output_dir='model_2/hls4ml_prj', part='xcu250-figd2104-2L-e'\n",
        ")\n",
        "hls_model.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jweahza-SrK9"
      },
      "source": [
        "# Create Quantized Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klvY2Omyc-QZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from callbacks import all_callbacks\n",
        "from tensorflow.keras.layers import Activation\n",
        "from qkeras.qlayers import QDense, QActivation\n",
        "from qkeras.quantizers import quantized_bits, quantized_relu\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    QDense(\n",
        "        64,\n",
        "        input_shape=(16,),\n",
        "        name='fc1',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "model.add(QActivation(activation=quantized_relu(6), name='relu1'))\n",
        "model.add(\n",
        "    QDense(\n",
        "        32,\n",
        "        name='fc2',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "model.add(QActivation(activation=quantized_relu(6), name='relu2'))\n",
        "model.add(\n",
        "    QDense(\n",
        "        32,\n",
        "        name='fc3',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "model.add(QActivation(activation=quantized_relu(6), name='relu3'))\n",
        "model.add(\n",
        "    QDense(\n",
        "        5,\n",
        "        name='output',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "model.add(Activation(activation='softmax', name='softmax'))\n",
        "\n",
        "\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
        "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
        "\n",
        "pruning_params = {\"pruning_schedule\": pruning_schedule.ConstantSparsity(0.75, begin_step=2000, frequency=100)}\n",
        "model = prune.prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "train = True\n",
        "if train:\n",
        "    adam = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
        "    callbacks = all_callbacks(\n",
        "        stop_patience=1000,\n",
        "        lr_factor=0.5,\n",
        "        lr_patience=10,\n",
        "        lr_epsilon=0.000001,\n",
        "        lr_cooldown=2,\n",
        "        lr_minimum=0.0000001,\n",
        "        outputDir='model_3',\n",
        "    )\n",
        "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
        "    model.fit(\n",
        "        X_train_val,\n",
        "        y_train_val,\n",
        "        batch_size=1024,\n",
        "        epochs=30,\n",
        "        validation_split=0.25,\n",
        "        shuffle=True,\n",
        "        callbacks=callbacks.callbacks,\n",
        "    )\n",
        "    # Save the model again but with the pruning 'stripped' to use the regular layer types\n",
        "    model = strip_pruning(model)\n",
        "    model.save('model_3/KERAS_check_best_model.h5')\n",
        "else:\n",
        "    from tensorflow.keras.models import load_model\n",
        "    from qkeras.utils import _add_supported_quantized_objects\n",
        "\n",
        "    co = {}\n",
        "    _add_supported_quantized_objects(co)\n",
        "    model = load_model('model_3/KERAS_check_best_model.h5', custom_objects=co)\n",
        "\n",
        "\n",
        "import hls4ml\n",
        "\n",
        "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
        "config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
        "config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
        "print(\"-----------------------------------\")\n",
        "hls_model = hls4ml.converters.convert_from_keras_model(\n",
        "    model, hls_config=config, output_dir='model_3/hls4ml_prj', part='xcu250-figd2104-2L-e'\n",
        ")\n",
        "hls_model.compile()\n",
        "\n",
        "y_qkeras = model.predict(np.ascontiguousarray(X_test))\n",
        "y_hls = hls_model.predict(np.ascontiguousarray(X_test))\n",
        "np.save('model_3/y_qkeras.npy', y_qkeras)\n",
        "np.save('model_3/y_hls.npy', y_hls)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB5DEv5pg2Cp"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_ref = load_model('model_1/KERAS_check_best_model.h5')\n",
        "y_ref = model_ref.predict(X_test)\n",
        "\n",
        "print(\"Accuracy baseline:  {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_ref, axis=1))))\n",
        "print(\"Accuracy pruned, quantized: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_qkeras, axis=1))))\n",
        "print(\"Accuracy hls4ml: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IO9AqdFMEUWA"
      },
      "outputs": [],
      "source": [
        "model1 = Sequential()\n",
        "model1.add(\n",
        "    QDense(\n",
        "        64,\n",
        "        input_shape=(16,),\n",
        "        name='fc1',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "model1.add(QActivation(activation=quantized_relu(6), name='relu1'))\n",
        "model1.add(\n",
        "    QDense(\n",
        "        32,\n",
        "        name='fc2',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "model1.add(QActivation(activation=quantized_relu(6), name='relu2'))\n",
        "model1.add(\n",
        "    QDense(\n",
        "        32,\n",
        "        name='fc3',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "model1.add(QActivation(activation=quantized_relu(6), name='relu3'))\n",
        "model1.add(\n",
        "    QDense(\n",
        "        5,\n",
        "        name='output',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "model1.add(Activation(activation='softmax', name='softmax'))\n",
        "\n",
        "\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
        "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
        "\n",
        "pruning_params = {\"pruning_schedule\": pruning_schedule.ConstantSparsity(0.75, begin_step=2000, frequency=100)}\n",
        "model1 = prune.prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "train = True\n",
        "if train:\n",
        "    adam = Adam(lr=0.0001)\n",
        "    model1.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
        "    callbacks = all_callbacks(\n",
        "        stop_patience=1000,\n",
        "        lr_factor=0.5,\n",
        "        lr_patience=10,\n",
        "        lr_epsilon=0.000001,\n",
        "        lr_cooldown=2,\n",
        "        lr_minimum=0.0000001,\n",
        "        outputDir='model_4',\n",
        "    )\n",
        "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
        "    model1.fit(\n",
        "        X_train_val,\n",
        "        y_train_val,\n",
        "        batch_size=1024,\n",
        "        epochs=30,\n",
        "        validation_split=0.25,\n",
        "        shuffle=True,\n",
        "        callbacks=callbacks.callbacks,\n",
        "    )\n",
        "    # Save the model again but with the pruning 'stripped' to use the regular layer types\n",
        "    model1 = strip_pruning(model)\n",
        "    model1.save('model_4/KERAS_check_best_model.h5')\n",
        "else:\n",
        "    from tensorflow.keras.models import load_model\n",
        "    from qkeras.utils import _add_supported_quantized_objects\n",
        "\n",
        "    co = {}\n",
        "    _add_supported_quantized_objects(co)\n",
        "    model1 = load_model('model_4/KERAS_check_best_model.h5', custom_objects=co)\n",
        "\n",
        "y_qkeras1 = model1.predict(np.ascontiguousarray(X_test))\n",
        "\n",
        "\n",
        "print(\"Accuracy pruned, quantized: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_qkeras, axis=1))))\n",
        "print(\"Accuracy quantized (new precision): {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_qkeras1, axis=1))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "js-hM7LrhChY"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy baseline:  {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_ref, axis=1))))\n",
        "print(\"Accuracy quantized (previous precision): ...\") # Add your previous accuracy result here\n",
        "print(\"Accuracy quantized (new precision): {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_qkeras, axis=1))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnhA67qpN-lG"
      },
      "outputs": [],
      "source": [
        "!pip install qkeras\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from sklearn.metrics import accuracy_score\n",
        "from qkeras import QDense, QActivation, quantized_bits, quantized_relu\n",
        "\n",
        "# Set your seed for reproducibility\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Define a function to build your model\n",
        "def build_quantized_model(input_shape, bits):\n",
        "    model = Sequential()\n",
        "    model.add(QDense(64, input_shape=(input_shape,), name='fc1',\n",
        "                     kernel_quantizer=quantized_bits(bits, 0, alpha=1),\n",
        "                     bias_quantizer=quantized_bits(bits, 0, alpha=1),\n",
        "                     kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "    model.add(QActivation(activation=quantized_relu(bits), name='relu1'))\n",
        "    model.add(QDense(32, name='fc2',\n",
        "                     kernel_quantizer=quantized_bits(bits, 0, alpha=1),\n",
        "                     bias_quantizer=quantized_bits(bits, 0, alpha=1),\n",
        "                     kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "    model.add(QActivation(activation=quantized_relu(bits), name='relu2'))\n",
        "    model.add(QDense(32, name='fc3',\n",
        "                     kernel_quantizer=quantized_bits(bits, 0, alpha=1),\n",
        "                     bias_quantizer=quantized_bits(bits, 0, alpha=1),\n",
        "                     kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "    model.add(QActivation(activation=quantized_relu(bits), name='relu3'))\n",
        "    model.add(QDense(5, name='output',\n",
        "                     kernel_quantizer=quantized_bits(bits, 0, alpha=1),\n",
        "                     bias_quantizer=quantized_bits(bits, 0, alpha=1),\n",
        "                     kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "    model.add(Activation('softmax'))\n",
        "    return model\n",
        "\n",
        "# Assuming X_train_val, y_train_val, X_test, y_test are loaded and preprocessed\n",
        "\n",
        "bit_precisions = [2, 4, 6, 8, 10, 12, 16]\n",
        "accuracies = []\n",
        "\n",
        "for bits in bit_precisions:\n",
        "    model = build_quantized_model(16, bits)\n",
        "    model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train your model\n",
        "    model.fit(X_train_val, y_train_val, batch_size=1024, epochs=30, validation_split=0.25, shuffle=True)\n",
        "\n",
        "    # Evaluate your model\n",
        "    predictions = model.predict(X_test)\n",
        "    accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    print(f\"Accuracy with {bits}-bit precision: {accuracy}\")\n",
        "\n",
        "# Save accuracies to a NumPy array file for further analysis\n",
        "np.save('quantized_model_accuracies.npy', np.array(accuracies))\n",
        "\n",
        "# To check and compare accuracies\n",
        "loaded_accuracies = np.load('quantized_model_accuracies.npy')\n",
        "print(\"Loaded Accuracies:\", loaded_accuracies)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}